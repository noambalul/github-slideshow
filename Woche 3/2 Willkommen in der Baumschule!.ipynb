{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "# [Nur Colab] Diese Zellen müssen nur auf *Google Colab* ausgeführt werden und installieren Packete und Daten\n",
        "!wget -q https://raw.githubusercontent.com/KI-Campus/AMALEA/master/requirements.txt && pip install --quiet -r requirements.txt\n",
        "!wget --quiet \"https://github.com/KI-Campus/AMALEA/releases/download/data/data.zip\" && unzip -q data.zip"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6-UejnySgaH",
        "outputId": "cbaf3e8c-6ac8-4d43-cffd-087535c52bee"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Willkommen in der Baumschule!   "
      ],
      "metadata": {
        "id": "nwq05s0OSgaJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Einführung\n",
        "\n",
        "Entscheidungsbäume sind die Bausteine einer der leistungsstärksten Methoden des **überwachten Lernens** (z. B. mit einer vordefinierten Zielvariablen), die heute verwendet werden. Falls Sie bereits eine Fehlerdiagnose bei einem Gerät, einem Auto oder einem Computer durchführen mussten, ist es gut möglich, dass Sie schon einmal einem Flussdiagramm zur Fehlerbehebung begegnet sind. Flussdiagramme sind visuelle Darstellungen von Entscheidungsbäumen. Zum Beispiel veröffentlicht die Higher School of Economics Informationsdiagramme, um das Leben ihrer MitarbeiterInnen zu erleichtern. Hier ist ein Ausschnitt aus der Anleitung für die Veröffentlichung eines Papers im Portal der Hochschule.\n",
        "<img src=\"https://github.com/KI-Campus/AMALEA/blob/master/Woche%203/images/snipped_GER.png?raw=1\">"
      ],
      "metadata": {
        "id": "52sfdHN1SgaS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Klassifizierungs- und Regressionsbäume (CART)\n",
        "\n",
        "Classification and Regression Trees (Klassifizierungs- und Regressionsbäume) ist ein Akronym, das 1984 von Leo Breiman eingeführt wurde. Es bezeichnet Entscheidungsbaum-Algorithmen, die für prädiktive Modellierungsprobleme verwendet werden können. Wir werden uns in dieser Übung auf den CART-Algorithmus konzentrieren."
      ],
      "metadata": {
        "id": "p5QlI37RSgaT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CART\n",
        "\n",
        "Das CART-Modell wird in Form eines binäreren Entscheidungsbaums dargestellt. Dabei handelt es sich um den gleichen binären Baum, den Sie vielleicht von Algorithmen und Datenstrukturen kennen. Jeder Knoten des Binärbaums kann null, einen oder zwei Kindknoten haben.\n",
        "\n",
        "Ein Knoten repräsentiert eine einzelne Eingabevariable (X) und einen Aufteilungspunkt (engl. split point) auf dieser Variable (vorausgesetzt, die Variable ist numerisch). Die Blatt- oder Endknoten des Baums enthalten eine Ausgangsvariable (Y), die für eine Vorhersage verwendet wird.\n",
        "\n",
        "Beim Erstellen eines binären Entscheidungsbaums wird der Eingaberaum aufgeteilt. Dazu wird das sogenannte rekursive binäre Splitting verwendet (greedy Ansatz). Hierbei handelt es sich um ein numerisches Verfahren, bei dem alle Werte aneinandergereiht werden und verschiedene Aufteilungspunkte mit Hilfe einer Kostenfunktion ausprobiert und bewertet werden.\n",
        "\n",
        "Der Split mit den besten Kosten (niedrigste Kosten, da wir die Kosten minimieren) wird ausgewählt. Alle Eingangsvariablen und alle möglichen Aufteilungspunkte werden ausgewertet und auf Grundlage der Kostenfunktion (greedy) ausgewählt.\n",
        "\n",
        "- **Regression:** Die Kostenfunktion, die zum Finden der Splitpunkte minimiert wird, ist die **Summe des quadrierten Fehlers** über alle Trainingsstichproben, die in das Rechteck fallen.\n",
        "\n",
        "- **Klassifizierung:** Es wird die *Gini*-Kostenfunktion verwendet, die einen Hinweis darauf liefert, wie rein die Knoten sind. Die Knotenreinheit bezieht sich dabei darauf, wie gemischt die jedem Knoten zugewiesenen Trainingsdaten sind.\n",
        "\n",
        "Die Aufteilung wird fortgesetzt, bis die Knoten eine Mindestanzahl von Trainingsbeispielen enthalten oder eine maximale Baumtiefe erreicht ist.\n",
        "\n",
        "In dieser Aufgabe konzentrieren wir uns nur auf die Klassifizierungseigenschaft des Algorithmus."
      ],
      "metadata": {
        "id": "XBOnE7xoSgaU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metriken\n",
        "\n",
        "#### Gini-Index\n",
        "\n",
        "Der Gini-Index ist die Kostenfunktion, die zum Bewerten der Aufteilungen des Datensatzes verwendet wird. Eine Aufteilung umfasst ein Eingabeattribut und einen Wert für dieses Attribut. Der Gini-Score gibt eine Vorstellung davon, wie gut eine Aufteilung ist, da er angibt, wie gemischt die Klassen in den beiden Gruppen sind, die durch die Aufteilung entstanden sind. Eine perfekte Aufteilung ergibt einen Gini-Score von 0, während die schlechteste Aufteilung, z. B. eine 50/50-Aufteilung, für ein Zwei-Klassen-Problem einen Gini-Score von 0,5 ergibt.\n",
        "\n",
        "Die Berechnung des Gini-Scores lässt sich am besten anhand eines Beispiels demonstrieren:\n",
        "\n",
        "<img src=\"https://github.com/KI-Campus/AMALEA/blob/master/Woche%203/images/iris_tree.png?raw=1\">\n",
        "\n",
        "Angenommen, Sie finden eine Irisblüte und wollen sie klassifizieren. In der obigen Abbildung beginnen wir im *Wurzelknoten*: Dieser Knoten überprüft, ob die Länge des Blütenblatts kleiner als 2,45 cm ist. Wenn das der Fall ist, gehen wir zum linken Kindknoten der Wurzel hinunter. Dieser Knoten ist ein *Blattknoten*, da er keine Kinder besitzt.\n",
        "\n",
        "Nehmen wir nun an, wir finden eine weitere Blume. Diese besitzt eine Blütenblattlänge, die größer als 2,45 cm ist. Angefangen bei der Wurzel kommen wir so zum rechten Kindknoten, der kein Blattknoten ist. Dieser Knoten möchte wissen, ob die Breite des Blütenblatts kleiner als 1,75 cm ist. Wenn das der Fall ist, dann ist unsere Blume höchstwahrscheinlich eine Iris-Versicolor. Andernfalls handelt es sich wahrscheinlich um eine Iris-Virginica.\n",
        "\n",
        "Angenommen, wir haben 100 Trainingsinstanzen mit einer Blütenblattlänge größer als 2,45 cm, darunter 54 mit einer Blütenblattbreite kleiner als 1,75 cm. Das Wertattribut eines Knotens gibt an, auf wie viele Trainingsinstanzen jeder Klasse dieser Knoten zutrifft: Der Knoten unten rechts trifft auf 0 Iris-Setosa, 1 Iris-Versicolor und 45 Iris-Virginica zu. Gemäß Gleichung (\\ref{eq1}) setzt sich der Gini-Score wie folgt zusammen: $1-(0/54)^2-(49/54)^2-(5/54)^2 = 0.168$.\n",
        "\n",
        "\\begin{equation*}\n",
        "G_i = 1 - \\sum_{k=0}^{n-1} p_{i,k}^2\n",
        "\\label{eq1}\\tag{1}\n",
        "\\end{equation*}\n",
        "wobei $p_{i,k}$ das Verhältnis der Instanzen der Klasse k unter den Trainingsinstanzen im $i^{th}$-Knoten beschreibt."
      ],
      "metadata": {
        "id": "599avyQZSgaU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importe"
      ],
      "metadata": {
        "id": "dG8q3ydgSgaV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "outputs": [],
      "metadata": {
        "id": "o86S7eHiSgaV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entscheidungsbäume mit scikit-learn\n",
        "\n",
        "Nun haben wir unseren Datensatz für die Algorithmen des maschinellen Lernens vorbereitet. Zu Beginn haben wir die Idee der Klassifizierung und Regression mit Entscheidungsbäumen beschrieben. Im Folgenden werden wir die Implementierung von Entscheidungsbäumen mittels scikit-learn verwenden, um die binäre Klassifizierung des Titanic Datensatzes durchzuführen.\n",
        "\n",
        "\n",
        "## Entscheidungsbäume ohne Parameteroptimierung (engl. parameter tuning)\n",
        "\n",
        "#### Importieren der Bibliotheken\n",
        "Der erste Schritt besteht darin, den Algorithmus \"wie er ist\" zu verwenden, ohne irgendwelche Parameter anzupassen. Importieren Sie daher die notwendige Bibliothek/Funktion von scikit-learn, die den DecisionTreeClassifier enthält. Außerdem muss die Funktion export_graphviz importiert werden, die für die Darstellung der Ergebnisse der Entscheidungsbäume benötigt wird. Um das Modell zu evaluieren, müssen wir ein Train- und ein Validation-Set erzeugen, indem wir den train-test split von scikit-learn verwenden. Importieren Sie daher die notwendigen Funktionen. Um die Performance der trainierten Entscheidungsbäume zu vergleichen, müssen wir zunächst den DummyClassifier importieren. Der DummyClassifer https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html ist in der Lage, Datenpunkte gleichmäßig zufällig zu klassifizieren oder immer das häufigste Label im Trainingssatz vorherzusagen. Importieren Sie den accuracy score des Pakets 'metrics' für die Evaluierung der Klassifizierungsergebnisse."
      ],
      "metadata": {
        "id": "-IGnmxxkSgaW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Aufgabe 3.2.1:</b> Importieren Sie die im Text oben genannten Funktionen.\n",
        "</div>"
      ],
      "metadata": {
        "id": "cYrj-4M1SgaW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Hinweis:</b> Falls graphviz nicht installiert ist, versuchen Sie folgende Schritte.  \n",
        "<ul>\n",
        "<li> 1. Ansatz: Öffnen Sie anaconda, anschließend gehen Sie zu den Umgebungen (engl. environments) und wählen Sie diejenige aus, an der Sie gerade arbeiten. Suchen Sie dann nach graphviz und installieren Sie es.\n",
        "<li> 2. Ansatz: Öffnen Sie ein Terminal innerhalb Ihrer Umgebung, indem Sie auf den grünen Pfeil Ihrer Umgebung klicken. Anschließend:\n",
        "<ul>\n",
        "<li> Aktivieren Sie Ihre Umgebung: conda activate environment_name\n",
        "    <li> Installieren Sie pip: conda install pip (gegebenfalls bereits installiert)\n",
        "    <li> installieren Sie graphviz: conda install python-graphviz\n",
        "    </ul>\n",
        "</li>\n",
        "\n",
        "</ul>\n",
        "<br>\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "wJZVSfjvSgaW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "# STUDENT CODE HERE\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "# STUDENT CODE until HERE\n",
        "\n",
        "from graphviz import Source"
      ],
      "outputs": [],
      "metadata": {
        "id": "4RyYepA6SgaX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generieren von Training-, Validierung- und Test-Datensatz\n",
        "\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Aufgabe 3.2.2:</b>\n",
        "<ul>\n",
        "<li>Laden Sie die Datensätze aus der Lösung der Vorbereitungsdatei (train_prepared.csv,...).\n",
        "<li>Nehmen Sie die Spalte mit den Labeldaten sowohl im Trainingsatz als auch im Testsatz und entfernen diese vom Datensatz.\n",
        "<li>Teilen Sie den \"train\"-Teil des Datensatzes in 80 % Trainingsdaten und 20 % Validierungsdaten auf. Verwenden Sie den Parameter random_state = 17 für die Reproduzierbarkeit der Ergebnisse.\n",
        "<li> Hinweis: Sie könnten den originalen Trainigsatz für das Kreuzvalidierungsverfahren (engl. Cross Validation) später benötigen.\n",
        "</ul>\n",
        "    \n",
        "<b>Wichtige Information:</b> Beim überwachten Lernen bestehen die Datensätze immer aus Labels und Features. Nachdem Sie Ihr Modell trainiert haben, geben Sie ihm neue Input Datensätze, die Features (Alter, Geschlecht usw.) enthalten; es gibt das vorhergesagte Label ('Survived') für diese Person zurück.<br>\n",
        "</div>"
      ],
      "metadata": {
        "id": "vCgSIlWbSgaX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "# STUDENT CODE HERE\n",
        "df_train = pd.read_csv('data/train_prepared.csv')\n",
        "df_test = pd.read_csv('data/test_prepared.csv')\n",
        "\n",
        "labels_train = df_train.pop('Survived')\n",
        "labels_test = df_test.pop('Survived')\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    df_train, labels_train, test_size=0.2, random_state=17)\n",
        "# STUDENT CODE until HERE"
      ],
      "outputs": [],
      "metadata": {
        "id": "URlogNjxSgaX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Validierung des Dummy Klassifikators\n",
        "\n",
        "Um einen Eindruck zu bekommen, ob die Klassifizierung mit dem Modell sinnvoll ist, verwenden wir den DummyClassifier, der zufällig entscheidet.  \n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Aufgabe 3.2.3:</b>\n",
        "<ul>\n",
        "<li> Trainieren Sie den Klassifikator mit dem entsprechenden Parameterwert 'most_frequent' für die Strategie\n",
        "<li> Benutzen Sie den Parameter random_state = 17 (für die Reproduzierbarkeit der Ergebnisse)\n",
        "<li> Berechnen Sie die Korrektklassifikationsrate (engl. accuracy), um die Klassifizierungsgenauigkeit für die Validierungsdaten zu erhalten\n",
        "<li> Hinweis: Besuchen Sie die Website von scikit-learn, um den Klassifikator zu importieren, ihn zu trainieren, mit ihm Vorhersagen zu treffen und die Korrektklassifikationsrate zu berechnen\n",
        "</ul>\n",
        "</div>"
      ],
      "metadata": {
        "id": "jc5_SyMOSgaY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "# STUDENT CODE HERE\n",
        "# DummyClassifier mit der Strategie 'most_frequent' erstellen\n",
        "dummy_clf = DummyClassifier(strategy='most_frequent', random_state=17)\n",
        "\n",
        "# Modell auf Trainingsdaten trainieren\n",
        "dummy_clf.fit(X_train, y_train)\n",
        "\n",
        "# Vorhersage auf Validierungsdaten\n",
        "y_pred_dummy = dummy_clf.predict(X_val)\n",
        "\n",
        "# Accuracy berechnen\n",
        "accuracy_dummy = accuracy_score(y_val, y_pred_dummy)\n",
        "\n",
        "# Ausgabe der Accuracy\n",
        "print(f\"Accuracy des DummyClassifier (most_frequent): {accuracy_dummy:.4f}\")\n",
        "# STUDENT CODE until HERE"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy des DummyClassifier (most_frequent): 0.5922\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ofl_aQnSgaY",
        "outputId": "d67a4927-3f9f-43a0-d41e-a05fe41dcabb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Frage 3.2.4:</b> Wie interpretieren Sie dieses Ergebnis?\n",
        "</div>\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Ihre Antwort:</b></div>\n"
      ],
      "metadata": {
        "id": "20kL_nM8SgaY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Validierung des Entscheidungsbaums\n",
        "\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Aufgabe 3.2.5:</b>\n",
        "<ul>\n",
        "<li> Trainieren Sie einen Entscheidungsbaum (mit DecisionTreeClassifier) mit einer maximalen Tiefe von 2\n",
        "<li> Evaluieren Sie die Korrektklassifikationsrate Metrik (engl. accuracy metric) anhand der Validierungsdaten.\n",
        "<li> Benutzen Sie den Parameter random_state = 17 für die Reproduzierbarkeit der Ergebnisse.\n",
        "<li> Hinweis: Syntax oder Funktionen mit diesem Klassifikator sind für Training etc. gleich.\n",
        "    </li>\n",
        "    \n",
        "</ul>\n",
        "</div>"
      ],
      "metadata": {
        "id": "F4EMLtZzSgaY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "# STUDENT CODE HERE\n",
        "# Entscheidungsbaum mit max. Tiefe von 2 und festem random_state\n",
        "tree_clf = DecisionTreeClassifier(max_depth=2, random_state=17)\n",
        "\n",
        "# Modell auf Trainingsdaten trainieren\n",
        "tree_clf.fit(X_train, y_train)\n",
        "\n",
        "# Vorhersage auf Validierungsdaten\n",
        "y_pred_tree = tree_clf.predict(X_val)\n",
        "\n",
        "# Accuracy berechnen\n",
        "accuracy_tree = accuracy_score(y_val, y_pred_tree)\n",
        "\n",
        "# Ausgabe der Accuracy\n",
        "print(f\"Accuracy des DecisionTreeClassifier (max_depth=2): {accuracy_tree:.4f}\")\n",
        "# STUDENT CODE until HERE"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy des DecisionTreeClassifier (max_depth=2): 0.7821\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Pk8m0YtSgaY",
        "outputId": "548be408-144e-400b-ef46-a8b0ab273539"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Frage 3.2.6:</b>  Was können Sie beobachten, wenn wir die Korrektklassifikationsrate mit der des DummyClassifiers vergleichen?\n",
        "</div>\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Ihre Antwort:</b></div>\n"
      ],
      "metadata": {
        "id": "5Ig2ikOrSgaY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Das trainierte Modell verstehen\n",
        "\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Aufgabe 3.2.7:</b>\n",
        "<ul>\n",
        "<li> Plotten Sie den Baum mit sklearn.tree.export_graphviz und graphviz\n",
        "<li> Geben Sie die Namen der Features sowie die Klassennamen entsprechend dem Datensatz aus.\n",
        "<li> Hinweis: Benutzen Sie dataframe.columns.values und Source(export_graphviz)\n",
        "</ul>\n",
        "</div>"
      ],
      "metadata": {
        "id": "X_LQtXMhSgaY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "# STUDENT CODE HERE\n",
        "# Feature-Namen und Klassen-Namen festlegen\n",
        "feature_names = list(X_train.columns.values)\n",
        "class_names = ['Nicht überlebt', 'Überlebt']  # 0 = Nicht überlebt, 1 = Überlebt\n",
        "\n",
        "# Exportiere den Baum als DOT-Datei und visualisiere ihn direkt\n",
        "dot_data = export_graphviz(\n",
        "    tree_clf,                       # Das trainierte Modell\n",
        "    out_file=None,                  # Keine Datei schreiben, direkt als String\n",
        "    feature_names=feature_names,    # Namen der Eingabe-Features\n",
        "    class_names=class_names,        # Namen der Zielklassen\n",
        "    filled=True,                    # Knoten farbig darstellen\n",
        "    rounded=True,                   # Abgerundete Knoten\n",
        "    special_characters=True         # Für Umlaute etc.\n",
        ")\n",
        "\n",
        "# Baum darstellen\n",
        "graph = Source(dot_data)\n",
        "graph\n",
        "# STUDENT CODE until HERE"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"574pt\" height=\"314pt\"\n viewBox=\"0.00 0.00 574.00 314.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 310)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-310 570,-310 570,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#f5ceb1\" stroke=\"black\" d=\"M342.5,-306C342.5,-306 219.5,-306 219.5,-306 213.5,-306 207.5,-300 207.5,-294 207.5,-294 207.5,-235 207.5,-235 207.5,-229 213.5,-223 219.5,-223 219.5,-223 342.5,-223 342.5,-223 348.5,-223 354.5,-229 354.5,-235 354.5,-235 354.5,-294 354.5,-294 354.5,-300 348.5,-306 342.5,-306\"/>\n<text text-anchor=\"start\" x=\"252\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Sex ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"249\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.47</text>\n<text text-anchor=\"start\" x=\"236\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 712</text>\n<text text-anchor=\"start\" x=\"215.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [443.0, 269.0]</text>\n<text text-anchor=\"start\" x=\"216\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Nicht überlebt</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#eb9d65\" stroke=\"black\" d=\"M262,-187C262,-187 140,-187 140,-187 134,-187 128,-181 128,-175 128,-175 128,-116 128,-116 128,-110 134,-104 140,-104 140,-104 262,-104 262,-104 268,-104 274,-110 274,-116 274,-116 274,-175 274,-175 274,-181 268,-187 262,-187\"/>\n<text text-anchor=\"start\" x=\"172\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 6.5</text>\n<text text-anchor=\"start\" x=\"165.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.299</text>\n<text text-anchor=\"start\" x=\"156\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 465</text>\n<text text-anchor=\"start\" x=\"150.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [380, 85]</text>\n<text text-anchor=\"start\" x=\"136\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Nicht überlebt</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M253.24,-222.91C247.16,-214.01 240.66,-204.51 234.39,-195.33\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"237.24,-193.3 228.71,-187.02 231.46,-197.25 237.24,-193.3\"/>\n<text text-anchor=\"middle\" x=\"224.09\" y=\"-207.89\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#7dbfee\" stroke=\"black\" d=\"M420,-187C420,-187 304,-187 304,-187 298,-187 292,-181 292,-175 292,-175 292,-116 292,-116 292,-110 298,-104 304,-104 304,-104 420,-104 420,-104 426,-104 432,-110 432,-116 432,-116 432,-175 432,-175 432,-181 426,-187 420,-187\"/>\n<text text-anchor=\"start\" x=\"325\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Pclass ≤ 2.5</text>\n<text text-anchor=\"start\" x=\"330\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.38</text>\n<text text-anchor=\"start\" x=\"317\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 247</text>\n<text text-anchor=\"start\" x=\"300\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [63.0, 184.0]</text>\n<text text-anchor=\"start\" x=\"313\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Überlebt</text>\n</g>\n<!-- 0&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>0&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M309.1,-222.91C315.26,-214.01 321.84,-204.51 328.19,-195.33\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"331.13,-197.24 333.95,-187.02 325.38,-193.25 331.13,-197.24\"/>\n<text text-anchor=\"middle\" x=\"338.42\" y=\"-207.92\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#acd6f4\" stroke=\"black\" d=\"M102,-68C102,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,0 12,0 12,0 102,0 102,0 108,0 114,-6 114,-12 114,-12 114,-56 114,-56 114,-62 108,-68 102,-68\"/>\n<text text-anchor=\"start\" x=\"21.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.465</text>\n<text text-anchor=\"start\" x=\"16\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 19</text>\n<text text-anchor=\"start\" x=\"14\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [7, 12]</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Überlebt</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M147.38,-103.73C134.79,-94.15 121.39,-83.96 108.87,-74.44\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"110.87,-71.57 100.79,-68.3 106.63,-77.14 110.87,-71.57\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#ea9a60\" stroke=\"black\" d=\"M266,-68C266,-68 144,-68 144,-68 138,-68 132,-62 132,-56 132,-56 132,-12 132,-12 132,-6 138,0 144,0 144,0 266,0 266,0 272,0 278,-6 278,-12 278,-12 278,-56 278,-56 278,-62 272,-68 266,-68\"/>\n<text text-anchor=\"start\" x=\"169.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.274</text>\n<text text-anchor=\"start\" x=\"160\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 446</text>\n<text text-anchor=\"start\" x=\"154.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [373, 73]</text>\n<text text-anchor=\"start\" x=\"140\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Nicht überlebt</text>\n</g>\n<!-- 1&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>1&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M202.49,-103.73C202.79,-95.52 203.11,-86.86 203.41,-78.56\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"206.92,-78.42 203.78,-68.3 199.92,-78.17 206.92,-78.42\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<path fill=\"#43a2e6\" stroke=\"black\" d=\"M404,-68C404,-68 314,-68 314,-68 308,-68 302,-62 302,-56 302,-56 302,-12 302,-12 302,-6 308,0 314,0 314,0 404,0 404,0 410,0 416,-6 416,-12 416,-12 416,-56 416,-56 416,-62 410,-68 404,-68\"/>\n<text text-anchor=\"start\" x=\"323.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.087</text>\n<text text-anchor=\"start\" x=\"314\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 131</text>\n<text text-anchor=\"start\" x=\"312\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 125]</text>\n<text text-anchor=\"start\" x=\"310\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Überlebt</text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M360.88,-103.73C360.66,-95.52 360.42,-86.86 360.19,-78.56\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"363.68,-78.2 359.91,-68.3 356.69,-78.39 363.68,-78.2\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<path fill=\"#f8fcfe\" stroke=\"black\" d=\"M554,-68C554,-68 446,-68 446,-68 440,-68 434,-62 434,-56 434,-56 434,-12 434,-12 434,-6 440,0 446,0 446,0 554,0 554,0 560,0 566,-6 566,-12 566,-12 566,-56 566,-56 566,-62 560,-68 554,-68\"/>\n<text text-anchor=\"start\" x=\"472\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"455\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 116</text>\n<text text-anchor=\"start\" x=\"442\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [57.0, 59.0]</text>\n<text text-anchor=\"start\" x=\"451\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Überlebt</text>\n</g>\n<!-- 4&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>4&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M413.39,-103.73C425.34,-94.24 438.05,-84.16 449.95,-74.72\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"452.38,-77.26 458.03,-68.3 448.02,-71.77 452.38,-77.26\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.sources.Source at 0x7e4eda208c90>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "wq4NabEWSgaZ",
        "outputId": "7523e354-e86f-492e-8a9d-a55fe1dcc9ac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BEFTkqSdUjcr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Frage 3.2.8:</b>  Welche Features werden für Vorhersagen im erstellten Entscheidungsbaum verwendet? Welche der verbleibenden Splits (in der letzten Zeile des Baums) ist derzeit die Präziseste?\n",
        "</div>\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Ihre Antwort:</b></div>\n"
      ],
      "metadata": {
        "id": "rFEspxWeSgaZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testen der Generalisierung\n",
        "\n",
        "In den vorherigen Aufgaben haben wir die Performance unseres Algorithmus an einem einzelnen Train-Test-Split unseres Training-Datensatzes evaluiert. Lassen Sie uns nun die Kreuzvalidierung (engl. cross validation) verwenden, um eine bessere Schätzung des Generalisierungsfehlers zu erhalten.\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Aufgabe 3.2.9:</b> Importieren Sie die notwendige Bibliothek für die Kreuzvalidierung (engl. cross validation) mit StratifiedKFold.\n",
        "</div>"
      ],
      "metadata": {
        "id": "8o8UUJLFSgaZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "# STUDENT CODE HERE\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "# STUDENT CODE until HERE"
      ],
      "outputs": [],
      "metadata": {
        "id": "a2qDN1tPSgaZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Aufgabe 3.2.10:</b>\n",
        "<ul>\n",
        "<li> Führen Sie eine 5-fache geschichtete Kreuzvalidierung (engl. 5-fold stratified cross validation) durch\n",
        "<li> Berechnen Sie die mittlere Korrektklassifikationsrate (engl. mean accuracy) und die Standardabweichung der Korrektklassifikationsrate (engl. accuracy)\n",
        "<li> Verwenden Sie eine maximale Tiefe von 2 und random_state = 17 für den Baum und die Folds\n",
        "<li> Vergessen Sie nicht, den gesamten Trainingssatz zu verwenden (bevor Sie ihn in train,val aufteilen)\n",
        "</ul>\n",
        "</div>"
      ],
      "metadata": {
        "id": "Y2wkUrWqSgaZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "# STUDENT CODE HERE\n",
        "# Entscheidungsbaum mit maximaler Tiefe 2 und festem Zufallszustand\n",
        "tree_clf = DecisionTreeClassifier(max_depth=2, random_state=17)\n",
        "\n",
        "# 5-fache geschichtete Kreuzvalidierung mit festem random_state\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)\n",
        "\n",
        "# Kreuzvalidierung: accuracy als Bewertungsmetrik\n",
        "scores = cross_val_score(tree_clf, X, y, cv=cv, scoring='accuracy')\n",
        "\n",
        "# Ausgabe der mittleren Accuracy und Standardabweichung\n",
        "print(f\"Mean Accuracy: {scores.mean():.4f}\")\n",
        "print(f\"Standardabweichung der Accuracy: {scores.std():.4f}\")\n",
        "# STUDENT CODE until HERE"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-1250ecd42719>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Kreuzvalidierung: accuracy als Bewertungsmetrik\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Ausgabe der mittleren Accuracy und Standardabweichung\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "hCzWkBF2SgaZ",
        "outputId": "b8db59dd-b676-4545-a47c-c71635f08a3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parameteroptimierung für Entscheidungsbäume\n",
        "\n",
        "Der wichtigste Parameter eines Entscheidungsbaums ist die Tiefe des Baums. Daher ist es notwendig, verschiedene Tiefen des Baums zu evaluieren, um die optimale Leistung hinsichtlich der Korrektklassifikationsrate (engl. classification accuracy) zu erreichen. Zu diesem Zweck verwenden wir die Gittersuche (engl. grid search) in Kombination mit dem Kreuzvalidierungsverfahren (engl. cross validation), das wir zuvor verwendet haben. Glücklicherweise hat scikit-learn bereits eine schöne und einfach zu bedienende Schnittstelle für dieses Problem implementiert. Die Funktion heißt `GridSearchCV` und ist in der Bibliothek sklearn.model_selection zu finden.\n",
        "\n",
        "\n",
        "#### Verwendung von Grid Search Cross-Validation zur Optimierung der Baumtiefe\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Aufgabe 3.2.11:</b>\n",
        "<ul>\n",
        "<li> Laden Sie die Bibliothek GridSearchCV und trainieren Sie einen Entscheidungsbaum (DecisionTreeClassifier, random_state = 17)\n",
        "<li> Ermitteln Sie die optimale maximale Tiefe mit 5-facher geschichteter Kreuzvalidierung (engl. 5-fold stratified cross-validation) und gleichem RandomState\n",
        "<li> Variieren Sie die Tiefe des Baums zwischen 1 und 13.\n",
        "<li> Vergessen Sie nicht, den gesamten Trainingssatz zu verwenden (bevor Sie ihn in train,val aufteilen)\n",
        "<li> Hinweis: Verwenden Sie die scikit-learn-Website für weitere Informationen zu den Funktionen\n",
        "</ul>\n",
        "</div>"
      ],
      "metadata": {
        "id": "LTbRiFfDSgaZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# STUDENT CODE HERE\n",
        "\n",
        "# STUDENT CODE until HERE"
      ],
      "outputs": [],
      "metadata": {
        "id": "tQG_5SPWSgaa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Aufgabe 3.2.12:</b>\n",
        "<ul>\n",
        "<li> Zeichnen Sie ein Diagramm zur Darstellung der durchschnittlichen Korrektklassifikationsrate über die Tiefe\n",
        "<li> Benutzen Sie das Attribut <code>.cv_results</code>, um die durchschnittliche Korrektklassifikationsrate mit Hilfe von 'mean_test_score' zu erhalten.\n",
        "</ul>\n",
        "</div>"
      ],
      "metadata": {
        "id": "pQkfPwVoSgaa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# STUDENT CODE HERE\n",
        "\n",
        "# STUDENT CODE until HERE"
      ],
      "outputs": [],
      "metadata": {
        "id": "gXMlwoK0Sgaa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Frage 3.2.13:</b>  Was sind die besten Parameterwerte? Wie hoch ist die Korrektklassifikationsrate (Kreuzvaliderungsverfahren) des Modells mit dieser Baumtiefe?\n",
        "</div>\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Ihre Antwort:</b></div>\n"
      ],
      "metadata": {
        "id": "tii1538KSgaa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# STUDENT CODE HERE\n",
        "\n",
        "# STUDENT CODE until HERE"
      ],
      "outputs": [],
      "metadata": {
        "id": "sUQUcrZ0Sgab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Für unsere Trainingsdaten haben wir den optimalen Parameter gefunden. Schließlich können wir die Perfomance bewerten, indem wir unsere Trainingsdaten zum Trainieren und unseren Testdatensatz zum Testen verwenden. Verwenden Sie im Folgenden immer eine Baumtiefe von 3.\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Aufgabe 3.2.14:</b>\n",
        "<ul>\n",
        "<li> Trainieren Sie einen Entscheidungsbaum bei einer Baumtiefe von drei, unter Verwendung aller Trainingsdaten (keine Kreuzvalidierung)\n",
        "<li> Berechnen Sie die Korrektklassifikationsrate (engl. accuracy) für den Testdatensatz. Verwenden Sie den Parameter random_state = 17 für die Reproduzierbarkeit.\n",
        "</ul>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "wnm6Nvh0Sgab"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# STUDENT CODE HERE\n",
        "\n",
        "# STUDENT CODE until HERE"
      ],
      "outputs": [],
      "metadata": {
        "id": "LIJmPibuSgab"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "dot_data = export_graphviz(\n",
        "    decision_tree, out_file=None, feature_names=x_train.columns.values, class_names=['Dead','Survived'],  filled=True,\n",
        "    rounded=True, special_characters=True\n",
        ")\n",
        "graph = Source(dot_data)\n",
        "graph"
      ],
      "outputs": [],
      "metadata": {
        "id": "0GgWhQHfSgab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vergleich von Ergebnissen mit der nicht optimierten Version\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Aufgabe 3.2.15:</b> Bestimmen Sie die Wirkung von GridSearchCV\n",
        "<ul>\n",
        "<li> Benutzen Sie folgenden Ausdruck: (acc2 - acc1) / acc1 * 100%\n",
        "<li> acc1 und acc2 sind die Korrektklassifikationsrate (engl. accuracies) der Kreuzvalidierung vor und nach der Optimierung von max_depth mit GridSearchCV\n",
        "<li> Hinweis: acc1 wurde bereits vor der Optimierung verwendet, berechnen Sie daher acc2 zum Vergleich\n",
        "<li> Geben Sie die Verbesserung (berechnet durch den Ausdruck) und die mittlere Korrektklassifikationsrate (engl. accuracy) des optimierten dec_tree aus. Verwenden Sie eine Baumtiefe von 3 und einen random_state = 17 für die Reproduzierbarkeit.\n",
        "</ul>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "ESnV1XtKSgab"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# STUDENT CODE HERE\n",
        "\n",
        "# STUDENT CODE until HERE"
      ],
      "outputs": [],
      "metadata": {
        "id": "WRF905dRSgab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Frage 3.2.16:</b> Was sind die Vorteile des \"grid search\" - Verfahrens?\n",
        "</div>\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Ihre Antwort:</b></div>\n"
      ],
      "metadata": {
        "id": "csvdczdcSgab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Einfluss der Skalierung\n",
        "\n",
        "Als letzten Schritt wollen wir den Einfluss unterschiedlicher Skalierungen auf unsere Trainingsdaten auswerten.\n",
        "\n",
        "##### Skalieren der Datensätze mit Standard Scaler und MinMaxScaler\n",
        "\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Aufgabe 3.2.17:</b>\n",
        "\n",
        "Laden Sie die in sklearn.preprocessing enthaltenen Funktionen für den StandardScaler und den MinMaxScaler.\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "RhjLh8fDSgag"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# STUDENT CODE HERE\n",
        "\n",
        "# STUDENT CODE until HERE"
      ],
      "outputs": [],
      "metadata": {
        "id": "TTlxgh_6Sgag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Aufgabe 3.2.18:</b> Bereiten Sie zwei verschiedene Datensätze vor, einen skaliert mit StandardScaler und den anderen mit MinMaxScaler.\n",
        "<ul>\n",
        "<li> Erstellen Sie die entsprechenden Skalierer und verwenden Sie die Methode <code>.fit_transform()</code> unter Verwendung des gesamten Trainingsdatensatzes\n",
        "<li> Transformieren Sie dann den Testdatensatz mit den angepassten Skalern mithilfe der Funktion transform\n",
        "    \n",
        "</ul>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "bHI88wr-Sgag"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# STUDENT CODE HERE\n",
        "\n",
        "# STUDENT CODE until HERE"
      ],
      "outputs": [],
      "metadata": {
        "id": "_POQjUIGSgag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluieren Sie die Leistung der skalierten Datensätze\n",
        "\n",
        "\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Aufgabe 3.2.19:</b> Trainieren Sie nun ein weiteres Entscheidungsbaummodell mit jedem der neu skalierten Datensätze (DecisionTreeClassifier, random_state = 17)\n",
        "<ul>\n",
        "<li> Berechnen Sie die Korrektklassifikationsrate des Testdatensatzes für beide Datensätze\n",
        "<li> Verwenden Sie eine maximale Tiefe von 3 für den Trainingsprozess\n",
        "\n",
        "</ul>\n",
        "</div>\n",
        "\n"
      ],
      "metadata": {
        "id": "Wce4uYl0Sgag"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Standard Scaler dataset\n",
        "# STUDENT CODE HERE\n",
        "\n",
        "# STUDENT CODE until HERE"
      ],
      "outputs": [],
      "metadata": {
        "id": "d0mfkgnXSgah"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# MinMax Scaler dataset\n",
        "# STUDENT CODE HERE\n",
        "\n",
        "# STUDENT CODE until HERE"
      ],
      "outputs": [],
      "metadata": {
        "id": "jU2KhC1gSgah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Frage 3.2.20:</b> Vergleichen Sie die Korrektklassifikationsrate (engl. accuracy) der Ergebnisse beider Skalierungsoptionen mit der ursprünglichen (ohne skalierte Datensätze) Leistung bei einer Baumtiefe von drei. Was stellen Sie fest? Warum entspricht dieses Ergebnis nicht den Erwartungen? (Vergleichen Sie es nicht mit dem Ergebnis der Kreuzvalidierung) Empfehlen Sie, die Skalierung generell anzuwenden?\n",
        "</div>\n",
        "\n",
        "<div class=\"alert alert-block alert-success\">\n",
        "<b>Ihre Antwort:</b></div>\n"
      ],
      "metadata": {
        "id": "5OP8ReNGSgah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RandomForests mit scikit-learn\n",
        "\n",
        "Wir verwenden nicht nur einen Entscheidungsbaum, sondern mehrere. Dadurch berücksichtigen wir Ausgaben mehrere Klassifikatoren als nur eine einzige (Ensemble-Methode - in diesem Fall Bagging). RandomForest-Klassifikatoren sind weniger anfällig für Overfit."
      ],
      "metadata": {
        "id": "3_b-VwSuSgah"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "random_forest = RandomForestClassifier(random_state=17)\n",
        "fold = StratifiedKFold(n_splits=5, random_state=17, shuffle=True)\n",
        "\n",
        "scores = cross_val_score(random_forest, X_train, Y_train, cv=fold)\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "outputs": [],
      "metadata": {
        "id": "uV0GpscySgah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fast so gut wie unser optimierter Entscheidungsbaum und besser als unsere nicht optimierte Version, da nur die Standardwerte von RandomForestClassifiers verwendet und nicht optimiert werden. Sie sollten dieses Werkzeug des maschinellen Lernens im Hinterkopf behalten."
      ],
      "metadata": {
        "id": "jk3gR86QSgah"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "q3d-2UYFSgai"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python-amalea"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}